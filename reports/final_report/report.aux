\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction to the Problem}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Definition of the Problem}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Data Description}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Encoding the Data}{2}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Nominal Categorical Variables}{2}{subsubsection.1.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Ordinal Categorical Variables}{2}{subsubsection.1.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Encoding Process}{2}{subsubsection.1.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Machine Learning Pipeline}{3}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Feature Selection}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}The Need for Feature Selection}{3}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feature Selection Technique}{3}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Greedy Subset Selection Results}{4}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Greedy Subset Selection - 46 features with highest weights.}}{4}{figure.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Machine Learning Models}{4}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Cross-Validation Technique: $k$-Fold CV}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Model $k$-Fold CV Results}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Perceptron}{6}{subsubsection.4.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Perceptron accuracy in 2,3,5-Fold CV}}{6}{figure.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}SVM}{6}{subsubsection.4.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces SVM accuracy in 2,3,5-Fold CV. From left to right, we are using linear, polynominal, and rbf kernels.}}{6}{figure.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Logistic Regression}{7}{subsubsection.4.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Logistic Regression accuracy in 2,3,5-Fold CV.}}{7}{figure.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}Adaboost}{7}{subsubsection.4.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Adaboost accuracy in 2,3,5-Fold CV. From left to right, we have 10 and 50 n\_estimators}}{7}{figure.5}}
